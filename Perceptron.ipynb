{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo: \n",
    "\n",
    "Modelo classificador de cuerpos de texto como spam o no spam, utilizando un simple perceptrón.\n",
    "\n",
    "## Paso 1. Definir una función de predicción:\n",
    "\n",
    "**Predict:**\n",
    "\n",
    "    Args:\n",
    "        - features [Float], length: n,    range:   0..1\n",
    "        - weights  [Float], length: n +1, range:  -1..1\n",
    "\n",
    "    Returns: Boolean value (Clasificamos algo como 'A' o 'B')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return True if activation >= 0.0 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Features: El resultado de varios atributos o 'features' que consideramos relevantes para nuestro modelo. Puede ser numero de palabras 'gatillo' en el correo, cantidad de ligas en el correo, numero de palabras solo en MAYUSCULAS etc... El punto es que este primer parametro va a ser un arreglo de tamaño n (donde n es el numero de features que estamos evaluando) y cada elemento estara normalizado para que sea un numero flotante entre 0 y 1.\n",
    "   \n",
    "    Ej: [0, .2, .12]\n",
    "\n",
    "    Esta entrada de ejemplo despues de ser procesada resulto un valor de 0 para el atributo de palabras gatillo, .2 para las ligas , y .12 para palabras en mayusculas.\n",
    "\n",
    "    Weights: Consiste en un arreglo de tamaño n+1 de numeros flotantes entre -1 y 1. \n",
    "    Los primeros n elementos de este arreglo juegan el papel de modificadores de la relevancia para nuestras n features a la hora de hacer el conteo final. Es decir, el resultado de nuestras features va a ser modificado por la importancia relativa de esa feature que esta representado por este 'peso'\n",
    "\n",
    "    El ultimo elemento de este arreglo es nuestro 'BIAS', no tiene una feature asociada que modifica, sino que modifica a toda la predicción en si. Es decir, si sabemos que de entrada es mucho mas probable que un correo sea spam a que sea legitimo entonces debemos tomar esa diferencia probabilistica en cuenta a la hora de hacer nuestra predicción. Por el otro lado, si la distribución real fuera 50/50 nuestro bias deberia ser de 0.\n",
    "\n",
    "    return: Vamos a decidir si retornamos cierto o falso (dispara la neurona o no dispara la neurona). Esto va a depender de la suma de todas las features multiplicadas por su peso mas el bias. Si esto nos da como resultado un numero mayor a 0 regresaremos 'true', de lo contrario regresaremos 'false' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2. Definir una funcion de entrenamiento:\n",
    "\n",
    "**Single_Train:**\n",
    "\n",
    "    Args:\n",
    "        - feature_l, ([Float], bool),  length: n,   range:   0..1\n",
    "        - weigths,    [Float],         length: n+1, range:  -1..1\n",
    "        - jump,        Float\n",
    "\n",
    "    Returns: A modified version of the weights argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def single_train(features_l, weights, jump):\n",
    "    prediction = predict(features_l[0], weights)\n",
    "    r_weight = random.randint(0, weights.length)\n",
    "    if prediction == features_l[1]:\n",
    "        if weights[r_weight] <= 0:\n",
    "            weights[r_weight] = ( (2 * sigmoid(jump - weights[r_weight]) ) -1)\n",
    "        else:\n",
    "            weights[r_weight] = ( (2 * sigmoid(jump + weights[r_weight]) ) -1 ) \n",
    "    else:\n",
    "        if weights[r_weight] <= 0:\n",
    "            weights[r_weight] = ( (2 * sigmoid(jump + weights[r_weight]) ) -1 )\n",
    "        else:\n",
    "            weights[r_weight] = ( (2 * sigmoid(jump - weights[r_weight]) ) -1 )\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Features_l: por features_labeled, es un tupla que contiene como primer elemento el arreglo que representa un arreglo de valores correspondientes a las features. El segudno elemento es un booleano representando la clasificación de este elemento.\n",
    "    \n",
    "    Weights: El mismo arreglo de pesos (en relacion a features) que se presento en la explicación de la funcion predict.\n",
    "    \n",
    "    Jump: La velocidiad de ajuste de nuestros pesos, ya sea reforzandolos o quitandoles importancia.\n",
    "    \n",
    "    return: Vamos a devolver una version modificada del argumento 'weights' en donde dependiendo del resultado de nuestra predicción (con la función predict) vis-a-vis el resultado ya conocido en nuestro dato etiquetado. En vez de modificar todos los pesos, tomaremos uno al azar y le sumaremos nuestro 'jump' de ahi a ese resultado le aplicaremos la funcion sigmoid (siempre resulta en un rango [0..1]) multiplicaremos ese resultado por dos y finalmente le restaremos 1. Terminando asi con un nuevo weight ajustado que siempre estara en el rango de [-1..1]  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Entrenar!\n",
    "\n",
    "**Train_all:**\n",
    "\n",
    "    Args:\n",
    "        - dataset,    [features_l], length: k\n",
    "        - iterations,  Int\n",
    "        - jump,        Float\n",
    "\n",
    "    Returns: An adjusted array of weights, ostensibly better suited for predition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012339457598623172"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_all(dataset, iterations, jump):\n",
    "    weights = map(lambda x: (x*2)-1, np.random.random_sample(dataset[0][0].length)).extend([0])\n",
    "    for _ in range(iterations):\n",
    "        for datum in dataset:\n",
    "            weights = single_train(datum, weights, jump)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41844232952670191, -0.1155226689624147, 0.47580779719647581, 0.43473757334835006, -0.67124382133333249, -0.61769772740092455, 0.70524508780893669, 0.13352452214363342, 0.61717351281934674, 0.22745345085184443, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = map(lambda x: (x*2)-1, np.random.random_sample(size= 10))\n",
    "arr.extend([0])\n",
    "print arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
